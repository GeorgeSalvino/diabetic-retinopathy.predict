{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referência: https://www.pyimagesearch.com/2017/12/11/image-classification-with-keras-and-deep-learning/\n",
    "\n",
    "TODO: adicionar comentários, mudar as camadas do modelo, criar dataset de teste, testar, criar pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retinopathy:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t# first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(20, (5, 5), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))         \n",
    "\t\t# second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "\thelp=\"path to input dataset\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "\thelp=\"path to output model\")\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output accuracy/loss plot\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "EPOCHS = 25\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('dataset')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, pre-process it, and store it in the data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (28, 28))\n",
    "\timage = img_to_array(image)\n",
    "\tdata.append(image)\n",
    "\n",
    "\t# extract the class label from the image path and update the\n",
    "\t# labels list\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\tlabel = 1 if label == \"symptoms\" else 0\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 1s 20ms/step - loss: 0.5522 - acc: 0.7129 - val_loss: 0.5603 - val_acc: 0.6938\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.5232 - acc: 0.7327 - val_loss: 0.5441 - val_acc: 0.7016\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5366 - acc: 0.7204 - val_loss: 0.5472 - val_acc: 0.6938\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5034 - acc: 0.7482 - val_loss: 0.5518 - val_acc: 0.6880\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5079 - acc: 0.7578 - val_loss: 0.5357 - val_acc: 0.7384\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5080 - acc: 0.7494 - val_loss: 0.5554 - val_acc: 0.7287\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5191 - acc: 0.7521 - val_loss: 0.5376 - val_acc: 0.7326\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5200 - acc: 0.7468 - val_loss: 0.5373 - val_acc: 0.7248\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5048 - acc: 0.7494 - val_loss: 0.5221 - val_acc: 0.7422\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5027 - acc: 0.7651 - val_loss: 0.5460 - val_acc: 0.7248\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4929 - acc: 0.7553 - val_loss: 0.5126 - val_acc: 0.7481\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4948 - acc: 0.7424 - val_loss: 0.5079 - val_acc: 0.7442\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4909 - acc: 0.7501 - val_loss: 0.5202 - val_acc: 0.7422\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4801 - acc: 0.7742 - val_loss: 0.5943 - val_acc: 0.7267\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5020 - acc: 0.7507 - val_loss: 0.5158 - val_acc: 0.7384\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4866 - acc: 0.7691 - val_loss: 0.5317 - val_acc: 0.7384\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4701 - acc: 0.7760 - val_loss: 0.5297 - val_acc: 0.7481\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4863 - acc: 0.7585 - val_loss: 0.5257 - val_acc: 0.7519\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4872 - acc: 0.7579 - val_loss: 0.5875 - val_acc: 0.7306\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4728 - acc: 0.7775 - val_loss: 0.5390 - val_acc: 0.7481\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4689 - acc: 0.7710 - val_loss: 0.5163 - val_acc: 0.7539\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4622 - acc: 0.7786 - val_loss: 0.5887 - val_acc: 0.7539\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4743 - acc: 0.7664 - val_loss: 0.5562 - val_acc: 0.7442\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4684 - acc: 0.7729 - val_loss: 0.5447 - val_acc: 0.7558\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4887 - acc: 0.7679 - val_loss: 0.5357 - val_acc: 0.7403\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = Retinopathy.build(width=28, height=28, depth=3, classes=2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)\n",
    " \n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"diabetic_retinopathy.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on symptom/nosymptoms\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
